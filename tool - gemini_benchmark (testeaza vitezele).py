import google.generativeai as genai
import os
from dotenv import load_dotenv
import time
from datetime import datetime

def benchmark_chat_models():
    """
    Acest script testeazÄƒ latenÈ›a (Time to First Token) pentru toate modelele de chat
    disponibile, trimiÈ›Ã¢nd o cerere simplÄƒ È™i mÄƒsurÃ¢nd timpul de rÄƒspuns.
    """
    print("=====================================================")
    print("â±ï¸  Benchmark de LatenÈ›Äƒ pentru Modelele Gemini")
    print("=====================================================\n")

    try:
        # Pasul 1: Configurare
        load_dotenv()
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            print("âŒ EROARE: Nu am gÄƒsit cheia 'GOOGLE_API_KEY' Ã®n fiÈ™ierul .env.")
            return

        genai.configure(api_key=api_key)
        print("âœ… Cheia API a fost Ã®ncÄƒrcatÄƒ È™i configuratÄƒ.")

        # Pasul 2: ObÈ›inerea modelelor eligibile pentru chat
        print("â³ Se obÈ›ine lista de modele de la Google...")
        all_models = genai.list_models()
        chat_models = [m for m in all_models if 'generateContent' in m.supported_generation_methods]
        
        if not chat_models:
            print("âš ï¸ Nu a fost gÄƒsit niciun model care sÄƒ suporte chat.")
            return
            
        print(f"âœ… Am gÄƒsit {len(chat_models)} modele eligibile pentru testare.\n")

        # Pasul 3: Testarea fiecÄƒrui model
        test_prompt = "Salut"
        results = []
        
        print(f"ğŸš€ Ãncep testarea. Ãntrebare de test pentru fiecare: '{test_prompt}'\n")

        for i, model in enumerate(chat_models):
            print(f"[{i+1}/{len(chat_models)}] Testez modelul: {model.name}...")
            
            try:
                # IniÈ›ializÄƒm modelul È™i pornim cronometrul
                model_instance = genai.GenerativeModel(model.name)
                start_time = time.perf_counter()

                # Trimitem cererea Ã®n mod streaming
                response_stream = model_instance.generate_content(test_prompt, stream=True)

                # AÈ™teptÄƒm primul chunk pentru a mÄƒsura TTFT
                # `next(iter(...))` este o modalitate rapidÄƒ de a obÈ›ine primul element
                first_chunk = next(iter(response_stream))

                # Oprim cronometrul imediat ce am primit primul rÄƒspuns
                end_time = time.perf_counter()
                
                duration_ms = (end_time - start_time) * 1000
                print(f"  â””â”€â”€> âœ… SUCCES! Timp de rÄƒspuns (TTFT): {duration_ms:.0f}ms\n")
                results.append({'name': model.name, 'time': duration_ms, 'status': 'Success'})

            except Exception as e:
                end_time = time.perf_counter()
                duration_ms = (end_time - start_time) * 1000
                error_message = str(e).split('\n')[0] # LuÄƒm doar prima linie a erorii
                print(f"  â””â”€â”€> âŒ EROARE! (dupÄƒ {duration_ms:.0f}ms) - {error_message}\n")
                results.append({'name': model.name, 'time': float('inf'), 'status': f'FAIL: {error_message}'})
        
        # Pasul 4: AfiÈ™area clasamentului
        print("\n=====================================================")
        print("ğŸ† CLASAMENT FINAL - Timp pÃ¢nÄƒ la Primul RÄƒspuns (TTFT)")
        print("=====================================================")
        
        successful_results = [r for r in results if r['status'] == 'Success']
        failed_results = [r for r in results if r['status'] != 'Success']

        # SortÄƒm rezultatele de la cel mai rapid la cel mai lent
        successful_results.sort(key=lambda x: x['time'])

        if not successful_results:
            print("\nNiciun model nu a rÄƒspuns cu succes.")
        else:
            for i, result in enumerate(successful_results):
                place = f"#{i+1}"
                if i == 0:
                    place += " ğŸ¥‡ CÃ¢È™tigÄƒtor"
                print(f"{place:<15} | {result['time']:>7.0f}ms | {result['name']}")
        
        if failed_results:
            print("\n-----------------------------------------------------")
            print("âš ï¸ Modele care au eÈ™uat testul:")
            print("-----------------------------------------------------")
            for result in failed_results:
                print(f"-> {result['name']} | Motiv: {result['status']}")

    except Exception as e:
        print(f"\nâŒ A apÄƒrut o eroare generalÄƒ Ã®n timpul scriptului: {e}")

if __name__ == "__main__":
    benchmark_chat_models()